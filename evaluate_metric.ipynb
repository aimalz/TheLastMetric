{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/aimalz/TheLastMetric/blob/master/MAFVariationalMutualInformationPzFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "talJxDz8s2CM"
   },
   "source": [
    "# `TheLastMetric`: An Information Metric for Observing Strategy Optimization for Photo-z\n",
    "\n",
    "Interpreting the results is half the fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy\n",
    "from astropy.table import Table\n",
    "from collections import namedtuple\n",
    "import corner\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sps\n",
    "\n",
    "from pzflow import Flow\n",
    "from pzflow.distributions import Uniform\n",
    "from pzflow.bijectors import Chain, StandardScaler, NeuralSplineCoupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['savefig.bbox'] = 'tight'\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyivJdJCvH7h"
   },
   "source": [
    "## Loading the data\n",
    "\n",
    "Assuming a fiducial underlying galaxy catalog, we use `OpSim` to generate observed galaxy catalogs under different observing strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EaSTqLUx-qSr",
    "outputId": "1ebe6afa-7cb6-4461-fe6c-dfc3c4d75063"
   },
   "outputs": [],
   "source": [
    "all_readme = open('dataset/readme.txt').read().split('\\n')\n",
    "\n",
    "in_metadata = []\n",
    "for i, line in enumerate(all_readme[0:6]):\n",
    "    descr = all_readme[i+1].split()\n",
    "    in_metadata.append(descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AGwfcqfd3K1n"
   },
   "outputs": [],
   "source": [
    "metadatum = namedtuple('metadatum', ['runid', 'OpSimName', 'u', 'g', 'r', 'i', 'z', 'y']) \n",
    "\n",
    "metadata = {}\n",
    "for row in in_metadata:\n",
    "    metadata[row[0]] = metadatum(*row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6IGkGcZlveO9"
   },
   "outputs": [],
   "source": [
    "names_z=('ID', 'z_true', 'z_phot', 'dz_phot', 'NN', 'N_train')\n",
    "names_phot=('ID', 'z_true', \n",
    "        'u', 'err_u', 'g', 'err_g', 'r', 'err_r', 'i', 'err_i', 'z', 'err_z', 'y', 'err_y', \n",
    "        'u-g', 'err_u-g', 'g-r', 'err_g-r', 'r-i', 'err_r-i', 'i-z', 'err_i-z', 'z-y', 'err_z-y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTBmWeZ_unn3"
   },
   "outputs": [],
   "source": [
    "# list of available catalogs\n",
    "available_os = list(metadata.keys())#[\"run_1_4_y10\", \"run_4_38_y10\", \"run_10_92_y10\", \"run_4_34_y10\", \"run_7_61_y10\", \"run_9_86_y10\"]\n",
    "names = [metadata[runid].OpSimName for runid in available_os\n",
    "    # \"baseline_v1_5_10yrs\",\n",
    "    # \"footprint_stuck_rollingv1_5_10yrs\",\n",
    "    # \"ddf_heavy_nexp2_v1_6_10yrs\",\n",
    "    # \"footprint_newAv1_5_10yrs\",\n",
    "    # \"third_obs_pt60v1_5_10yrs\",\n",
    "    # \"barebones_v1_6_10yrs\",\n",
    "]\n",
    "os_names = dict(zip(available_os, names))\n",
    "colors = [\"k\", \"plum\", \"cornflowerblue\", \"#2ca02c\", \"gold\", \"tomato\"]\n",
    "os_colors = dict(zip(available_os, colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w0SZFBkerVyq",
    "outputId": "1360fe9d-fb78-4c64-ea96-880e9f24d4af"
   },
   "outputs": [],
   "source": [
    "phot_cats, z_cats = {}, {}\n",
    "for an_os in available_os:\n",
    "    one_os = 'run_'+an_os\n",
    "    test_cat = Table.read('dataset/'+one_os+'/test.cat', format='ascii')\n",
    "\n",
    "    z_cat = Table.read('dataset/'+one_os+'/zphot.cat', \n",
    "                       format='ascii', \n",
    "                       names=names_z)\n",
    "\n",
    "    phot_cat = Table.read('dataset/'+one_os+'/test.cat', \n",
    "                       format='ascii', \n",
    "                       names=names_phot)\n",
    "    phot_cat = Table.from_pandas(phot_cat.to_pandas().dropna())\n",
    "    phot_cats[an_os] = phot_cat\n",
    "    limmags = []\n",
    "    for band in ['u', 'g', 'r', 'i', 'z', 'y']:\n",
    "        limmags.append(max(phot_cat[band]))\n",
    "    limmag = metadatum(an_os, os_names[an_os], *limmags)\n",
    "    print((metadata[an_os], '\\n'))\n",
    "    print(limmag)\n",
    "    z_cats[an_os] = z_cat\n",
    "\n",
    "# yes, all galaxies are within the magnitude limits, and usually by a large margin rather than right up to the limit, oddly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot limiting magnitudes for each opsim run and observed sample magnitude extrema (as boxplot) for each opsim run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRAGpkimzcb3"
   },
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_for_corner(one_os, labels):\n",
    "    return np.array([phot_cats[one_os][label] for label in labels]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 984
    },
    "id": "B0LJEmb4y6Qk",
    "outputId": "a82269c2-db5a-4a6f-8708-eb1c416651a8"
   },
   "outputs": [],
   "source": [
    "# labels = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "\n",
    "# for i, which_os in enumerate(available_os):\n",
    "#     if i == 0:\n",
    "#         fig = corner.corner(prep_for_corner(available_os[i], labels), labels=labels, alpha=0.25)\n",
    "#     else:\n",
    "#         corner.corner(prep_for_corner(which_os, labels), fig=fig, color=os_colors[which_os], alpha=0.25)\n",
    "#   # corner.overplot_points(fig, [float(metadata[which_os][i+2]) for i in range(6)], color=os_colors[which_os], alpha=0.5)\n",
    "#   # not sure why the overplotting of limits (as lines or points) fails given corner's documentation. . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "vbc59PeVlcil",
    "outputId": "3f2841f9-9253-4234-c39f-1d32535ae8a6"
   },
   "outputs": [],
   "source": [
    "labels = ['u-g', 'g-r', 'r-i', 'i-z', 'z-y']\n",
    "\n",
    "for i, which_os in enumerate(available_os):\n",
    "    if i == 0:\n",
    "        fig = corner.corner(prep_for_corner(available_os[i], labels), labels=labels, alpha=0.25)\n",
    "    else:\n",
    "        corner.corner(prep_for_corner(which_os, labels), fig=fig, color=os_colors[which_os], alpha=0.25)\n",
    "\n",
    "# note to self: try some of these tricks https://github.com/tommasotreu/AARV/blob/master/attic/spare-or-old-figures/DdtDa.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LifY_m5j88at"
   },
   "outputs": [],
   "source": [
    "# labels = ['err_u', 'err_g', 'err_r', 'err_i', 'err_z', 'err_y']\n",
    "\n",
    "# for i, which_os in enumerate(available_os):\n",
    "#     if i == 0:\n",
    "#         fig = corner.corner(np.log(prep_for_corner(available_os[i], labels)), \n",
    "#                             labels=['log-'+label for label in labels], alpha=0.25)\n",
    "#     else:\n",
    "#         corner.corner(np.log(prep_for_corner(which_os, labels)), fig=fig, color=os_colors[which_os], alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['err_u-g', 'err_g-r', 'err_r-i', 'err_i-z', 'err_z-y']\n",
    "\n",
    "for i, which_os in enumerate(available_os):\n",
    "    if i == 0:\n",
    "        fig = corner.corner(np.log(prep_for_corner(available_os[i], labels)), \n",
    "                            labels=['log-'+label for label in labels], alpha=0.25)\n",
    "    else:\n",
    "        corner.corner(np.log(prep_for_corner(which_os, labels)), fig=fig, color=os_colors[which_os], alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = np.linspace(0,3.5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "giQ6d2g0zImm",
    "outputId": "eac8ddfd-b47f-4037-cbf6-35a1603d9593"
   },
   "outputs": [],
   "source": [
    "for which_os in available_os:\n",
    "    plt.hist(z_cats[which_os]['z_true'], bins=tx, alpha=0.5, histtype='step',\n",
    "       color=os_colors[which_os], label=os_names[which_os])#+': '+str(len(phot_cats[which_os]))+' galaxies')\n",
    "xlabel(r'true redshift $z$')\n",
    "ylabel('number of galaxies')\n",
    "legend(loc='upper right', fontsize='small')\n",
    "# semilogy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the entropy $H(z)$ and show it's the same across OpSim runs (or, keep the calculated values and factor them into overall metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-guYIy1xLBy"
   },
   "outputs": [],
   "source": [
    "def calc_entropy(samp, bins=None):\n",
    "    [heights, grid] = np.histogram(samp, bins=bins, density=True)\n",
    "    filtered = np.where(heights > 0.)\n",
    "    return np.dot(heights[filtered] * np.log(heights[filtered]), (grid[1:] - grid[:-1])[filtered])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies = {}\n",
    "for which_os in available_os:\n",
    "    entropies[which_os] = calc_entropy(z_cats[which_os]['z_true'], bins=tx)\n",
    "print(np.mean(list(entropies.values())))\n",
    "print(np.std(list(entropies.values())))\n",
    "print(np.std(list(entropies.values())) / np.mean(list(entropies.values())))\n",
    "# conclusion, these entropies are close to each other to within 0.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MuRFvLbDAmvs"
   },
   "outputs": [],
   "source": [
    "# TODO: want to plot the CMNN photo-z summary stats here\n",
    "# hope to establish expectations: (nexp, barebones) are pretty good, (twilight, filterdist, stuck) seem pretty bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8e-Xq4JvGDs"
   },
   "source": [
    "## Approximating the Mutual Information Lower Bound\n",
    "\n",
    "We use a normalizing flow to approximate the distribution of redshift and photometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4zfw77XE7fl"
   },
   "outputs": [],
   "source": [
    "flows = {}\n",
    "for os in available_os:\n",
    "    flows[os] = Flow(file=f\"trained_flows/flow_for_run_{os}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RoFaZP50OQxp"
   },
   "outputs": [],
   "source": [
    "# TODO: check that draws from trained flow look like original data\\\n",
    "# well, can only check in redshift because conditional flows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: need to experiment with different fit parameters because this might be too smooth, also does it account for photometric errors?\n",
    "# data for this now exists as f\"trained_flows/flow_for_run_{os}_K=\"+k+\".pkl\" \n",
    "# for k=str(2), str(8), str(32), and default was 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KF3_XcFvIgz6"
   },
   "outputs": [],
   "source": [
    "# load the catalogs\n",
    "catalogs = dict()\n",
    "for os in available_os:\n",
    "    z_cat = pd.read_csv(f\"dataset/run_{os}/zphot.cat\", names=names_z, delim_whitespace=True, skiprows=1)\n",
    "    phot_cat = pd.read_csv(f\"dataset/run_{os}/test.cat\", names=names_phot, delim_whitespace=True)\n",
    "    cat = z_cat.merge(phot_cat)\n",
    "    catalogs[os] = cat.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6XQH9jAGitD"
   },
   "outputs": [],
   "source": [
    "# this just makes the posteriors for plotting, not sure why it uses so much memory. . .\n",
    "all_logp = {}\n",
    "for which_os in available_os:\n",
    "    flow = flows[which_os]\n",
    "    cat = catalogs[which_os]\n",
    "    logp = flow.posterior(flow.info[\"condition_scaler\"](cat), column=\"z_true\", grid=tx)\n",
    "    all_logp[which_os] = logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oC3AFenn-BUu",
    "outputId": "2df387d2-47c6-4b7e-b598-a3deb6bcffaf"
   },
   "outputs": [],
   "source": [
    "fig, ax = subplots(len(available_os), 1, figsize=(5, 3*len(available_os)))\n",
    "for i, which_os in enumerate(available_os):\n",
    "    ax[i].set_ylabel(r'posterior $q_{\\theta}(z | x_{phot})$')\n",
    "#     ax[i].set_title(os_names[which_os])\n",
    "    logp = all_logp[which_os]\n",
    "    batch = catalogs[which_os]\n",
    "    for j, ind in enumerate([0, 10, 100, 1000, 10000]):\n",
    "        dx = (max(tx) - min(tx))/len(tx)\n",
    "        plotpdf = logp[ind] / np.sum(logp[ind] * dx)\n",
    "        ax[i].plot(tx, plotpdf, color=colors[j+1], alpha=0.75, \n",
    "                   label='model photo-z posterior for galaxy '+str(ind))\n",
    "        cmnn_eval = sps.norm(batch['z_phot'][ind], batch['dz_phot'][ind]).pdf(tx)\n",
    "        ax[i].plot(tx, cmnn_eval, color=colors[j+1], alpha=0.75, linestyle='--',\n",
    "                   label='CMNN photo-z posterior for galaxy '+str(ind))\n",
    "#         hival = np.max(np.max(plotpdf), np.max(cmnn_eval))\n",
    "        ax[i].vlines(batch['z_true'][ind], 0., 10., color=colors[j+1], alpha=0.25,\n",
    "                      label='true redshift of galaxy '+str(ind))\n",
    "        ax[i].vlines(batch['z_phot'][ind], 0., 10., color=colors[j+1], alpha=0.75, linestyle='--',\n",
    "                      label='CMNN-estimated redshift of galaxy '+str(ind))\n",
    "        \n",
    "#     ax[i].plot(tx, (logp[100]), color='#9467bd',  label='photo-z posterior for galaxy 100')\n",
    "#     ax[i].axvline(batch['z_true'][100], linestyle='--', color='#9467bd', label='true redshift of galaxy 100')\n",
    "#     ax[i].plot(tx, (logp[1000]), color='#8c564b', label='photo-z posterior for galaxy 1000')\n",
    "#     ax[i].axvline(batch['z_true'][1000], linestyle='--', color='#8c564b', label='true redshift of galaxy 1000')\n",
    "  # ax[i].legend(loc='upper right')\n",
    "#     if i == 3:\n",
    "#         ax[i].set_xlabel(r'redshift $z$')\n",
    "    ax[i].text(1, 8, os_names[which_os])\n",
    "    ax[i].set_xlim(0, 2.5)\n",
    "    ax[i].set_ylim(0., 10.)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.0)\n",
    "fig.show()\n",
    "# TODO: maybe choose spread of redshifts or from particular places in color space?\n",
    "# TODO: also plot CMNN estimates and Gaussian error bars here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating and interpreting the metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5X5XXnIHg5J"
   },
   "source": [
    "The above plot should show the redshift posterior distribution for given photometry $q_\\theta(z | x_{phot})$. \n",
    "\n",
    "We are going to use that to compute our lower bound on the mutual information\n",
    "\n",
    "$$I(z; x_{phot})  \\geq \\mathbb{E}_{z, x_{phot}} \\left[ q_\\theta(z | x_{phot}) \\right]  + H(z)$$ \n",
    "\n",
    "The second term in this bound only depends on the true redshift distribution, which stays constant between observing strategies. Only the first term depends on the observed photometry, so it is the only one we have to compare between `OpSim` runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "At8IrQ2s4NKl",
    "outputId": "9482cfca-6c90-4ce6-d1db-ee8eab2a6707"
   },
   "outputs": [],
   "source": [
    "all_milb = {}\n",
    "for which_os in available_os:\n",
    "    phot_cat = catalogs[which_os]\n",
    "\n",
    "    mutual_information_lower_bound = flows[which_os].log_prob(flows[which_os].info[\"condition_scaler\"](phot_cat))\n",
    "    all_milb[which_os] = mutual_information_lower_bound + entropies[which_os]\n",
    "    print((os_names[which_os], np.mean(mutual_information_lower_bound)))\n",
    "# TODO: make this an actual expected value rather than just sum\n",
    "# also, shouldn't it be sum of exponential of metric value, since it should never penalize a negative value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean of metric values pretty much tells us what we want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "gMUk6T3uNlIx",
    "outputId": "9968a151-17b6-4015-95c8-d943965def73"
   },
   "outputs": [],
   "source": [
    "# surprisingly not so different from one another\n",
    "for which_os in available_os:\n",
    "    mutual_information_lower_bound = all_milb[which_os].flatten()\n",
    "    print((np.mean(mutual_information_lower_bound), np.std(mutual_information_lower_bound)))\n",
    "    hist(mutual_information_lower_bound, bins=np.linspace(-16, 5, 100), alpha=0.75, histtype='step', \n",
    "       color=os_colors[which_os], label=os_names[which_os], density=False)\n",
    "    xlabel(r'$\\mathbb{E}_{z, x_{phot}} \\left[ q_\\theta(z | x_{phot}) \\right]$')\n",
    "xlim(-5.5, 5.)\n",
    "legend(loc='upper left')\n",
    "# semilogy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seeking a redshift-dependent visualization of metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist2d(z_cats['1_4_y10']['z_true'], all_milb['1_4_y10'].flatten(), \n",
    "#                   bins=[np.linspace(0., 3., 50), np.log(np.linspace(np.exp(-5.), np.exp(5.), 100))]\n",
    "#                  )\n",
    "# plt.xlabel('redshift')\n",
    "# plt.ylabel(r'$\\mathbb{E}_{z, x_{phot}} \\left[ q_\\theta(z | x_{phot}) \\right]$')\n",
    "# plt.title(os_names['1_4_y10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8cLxM3Gx7z4M",
    "outputId": "2aae713e-cd55-4594-f877-ff1046a887f9"
   },
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(len(available_os), 1, figsize=(5, 5*len(available_os)))\n",
    "# for i, which_os in enumerate(available_os):\n",
    "#     axs[i].hist2d(z_cats[which_os]['z_true'], all_milb[which_os].flatten(), \n",
    "#                   bins=[np.linspace(0., 3., 50), np.log(np.linspace(np.exp(-5.), np.exp(5.), 100))]\n",
    "#                  )\n",
    "#     axs[i].set_xlabel('redshift')\n",
    "#     axs[i].set_ylabel(r'$\\mathbb{E}_{z, x_{phot}} \\left[ q_\\theta(z | x_{phot}) \\right]$')\n",
    "#     axs[i].set_title(os_names[which_os])\n",
    "# # they're different, but not visibly so\n",
    "# # TODO: plot violins of metric as a function of binned redshift so they're all on one set of axes? or quantiles because outlers? or box/whisker https://matplotlib.org/stable/gallery/pyplots/boxplot_demo_pyplot.html?\n",
    "# # TODO: normalize within redshift bins to get these on one set of axes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: replace this with Francois' version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minitx = np.linspace(0., 3.5, 35)\n",
    "\n",
    "def marginal_mean(which_os):\n",
    "    inx = minitx\n",
    "    iny = np.linspace(-5., 5., 50)\n",
    "    res = np.histogram2d(z_cats[which_os]['z_true'], all_milb[which_os].flatten(), \n",
    "               bins=[inx, iny], density=True)\n",
    "    zgrid, egrid = np.meshgrid(inx[:-1], iny[:-1])\n",
    "    dy = (iny[1:] - iny[:-1]) / len(iny)\n",
    "    nz = np.histogram(z_cats[which_os]['z_true'], bins=minitx)\n",
    "    return np.sum(res[0] * egrid.T * dy, axis=1)\n",
    "\n",
    "base_marg_sum = marginal_mean(available_os[0])\n",
    "for which_os in available_os:\n",
    "    resy = marginal_mean(which_os)\n",
    "#     toplot = (res - base_marg_sum) / base_marg_sum\n",
    "    plt.plot(minitx[1:], resy, color=os_colors[which_os], alpha=0.75, label=os_names[which_os])\n",
    "plt.xlabel(r'$z$')\n",
    "plt.ylabel(r'$\\langle\\mathbb{E}_{z, x_{phot}} \\left[ q_\\theta(z | x_{phot}) \\right](z)\\rangle$')\n",
    "plt.legend(loc='upper right')\n",
    "# plt.legend(loc='lower left')\n",
    "# plt.ylim(0.95, 1.01)\n",
    "# plt.semilogy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minitx = np.linspace(0., 3.5, 25)\n",
    "\n",
    "# def marginal_sum(which_os):\n",
    "#     res = np.histogram2d(z_cats[which_os]['z_true'], all_milb[which_os].flatten(), \n",
    "#                bins=[minitx, np.log(np.linspace(np.exp(-5.), np.exp(5.), 50))])\n",
    "#     return np.sum(res[0], axis=1)\n",
    "\n",
    "# base_marg_sum = marginal_sum(available_os[0])\n",
    "# for which_os in available_os:\n",
    "#     res = marginal_sum(which_os)\n",
    "#     toplot = (res - base_marg_sum) / base_marg_sum\n",
    "#     plt.plot(minitx[1:], toplot, color=os_colors[which_os], alpha=0.5, label=os_names[which_os])\n",
    "# plt.xlabel(r'$z$')\n",
    "# plt.ylabel(r'$\\mathbb{E}_{z, x_{phot}} \\left[ q_\\theta(z | x_{phot}) \\right](z)$')\n",
    "# plt.legend(loc='lower left')\n",
    "# # plt.semilogy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WiWnnfFk3bIT"
   },
   "outputs": [],
   "source": [
    "# something isn't right about the autocalculation of moments so doing it by hand\n",
    "def calc_moment(vals, k):\n",
    "    n = len(vals)\n",
    "    outval = np.sum(vals**k) / float(n)\n",
    "    return float(outval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5oDT3aEfS5_i"
   },
   "outputs": [],
   "source": [
    "which_moments = range(0, 5)\n",
    "moment_res = {}\n",
    "for which_os in available_os:\n",
    "  # print((np.mean(all_milb[which_os]), np.std(all_milb[which_os])))\n",
    "    moment_res[which_os] = []\n",
    "    for i in which_moments:\n",
    "        moment_res[which_os].append(calc_moment(all_milb[which_os], k=i))#sps.mstats.moment(all_milb[which_os], moment=which_moments[i], axis=0))\n",
    "# print(moment_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17gQaWeBU6VX"
   },
   "outputs": [],
   "source": [
    "# rescaled_moments = {}\n",
    "# for which_os in available_os:\n",
    "#   rescaled_moments[which_os] = []\n",
    "# for n in which_moments:\n",
    "#   vals = np.array([moment_res[which_os][n] for which_os in available_os])\n",
    "#   # print(vals)\n",
    "#   avg = np.mean(vals)\n",
    "#   span = max(vals) - min(vals)\n",
    "#   for which_os in available_os:\n",
    "#     rescaled_moments[which_os].append((moment_res[which_os][n] - avg) / span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 894
    },
    "id": "z9qXZSTuTwhB",
    "outputId": "0f62caf9-9a02-40c9-f2dd-9c90f9ba29f9"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(which_moments), 1, figsize=(len(which_moments), 15))\n",
    "for i in which_moments:\n",
    "    for which_os in available_os:\n",
    "        axs[i].vlines(moment_res[which_os][i], -1., 1., color=os_colors[which_os], alpha=0.5, label=os_names[which_os])\n",
    "    axs[i].set_xlabel('moment='+str(i))\n",
    "axs[0].legend()\n",
    "# TODO try bootstrap samples to give this some depth\n",
    "# variance is really divergent between stuck, ddf, new vs. third, barebones, baseline; suspect this is due to outliers. . . hence why bootstrap could help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(which_moments), 1, figsize=(len(which_moments), 15))\n",
    "for i in which_moments:\n",
    "    for which_os in available_os:\n",
    "        axs[i].vlines((moment_res[which_os][i])**(1./(max(i, 1.))), -1., 1., color=os_colors[which_os], alpha=0.5, label=os_names[which_os])\n",
    "    axs[i].set_xlabel('moment='+str(i))\n",
    "axs[0].legend()\n",
    "# TODO try bootstrap samples to give this some depth\n",
    "# variance is really divergent between stuck, ddf, new vs. third, barebones, baseline; suspect this is due to outliers. . . hence why bootstrap could help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3N56BmOLieI"
   },
   "outputs": [],
   "source": [
    "# # TODO: get rid of diagonal\n",
    "# fig, ax = subplots(len(available_os), len(available_os), figsize=(len(available_os)-1, 20), sharey=True, sharex=True)\n",
    "# hists = {}\n",
    "# for j, base_os in enumerate(available_os):\n",
    "#   phot_cat = phot_cats[base_os]\n",
    "#   mutual_information_lower_bound = all_milb[base_os]\n",
    "#   x = onp.linspace(0., 2.5, 64)\n",
    "#   y = onp.linspace(-5., 1., 64)\n",
    "#   h, x, y = onp.histogram2d(phot_cat['z_true'], mutual_information_lower_bound.flatten(), bins=(x, y), density=True)#64)#, extent=np.array([[0.,2.5], [-5.,1.]]))\n",
    "#   hists[base_os] = h\n",
    "# extrema = [0., 0.]\n",
    "# for j, base_os in enumerate(available_os):\n",
    "#   for i, comp_os in enumerate(available_os):\n",
    "#     diff_hist = hists[base_os] - hists[comp_os]\n",
    "#     comp_extrema = [onp.min(diff_hist), onp.max(diff_hist)]\n",
    "#     extrema = [min(comp_extrema[0], extrema[0]), max(comp_extrema[1], extrema[1])]\n",
    "#     img = ax[j][i].imshow(diff_hist.T, origin='lower', cmap=mpl.cm.viridis_r, vmin=-0.4, vmax=0.4, extent=[0.,2.5,-5.,1.], aspect='auto')\n",
    "#     ax[j][i].text(0., 1.1, base_os+' - '+comp_os)\n",
    "#     ax[j][i].set_ylabel(r'$\\Delta\\mathbb{E}_{z, x_{phot}} \\left[ q_\\theta(z | x_{phot}) \\right]$')\n",
    "#     fig.colorbar(img, ax=ax[j][i])\n",
    "#     ax[j][i].set_xlabel(r'redshift $z$')\n",
    "# fig.tight_layout()\n",
    "# fig.show()\n",
    "# print(extrema)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "MAFVariationalMutualInformationPzFlow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "LSST-DESC (Python 3)",
   "language": "python",
   "name": "lsstdesc_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
